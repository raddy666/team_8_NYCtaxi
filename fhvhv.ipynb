{
  "metadata": {
    "name": "fhvhv",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql import SparkSession\r\nfrom pyspark.sql.functions import col, concat, lit, to_timestamp, avg, month, when, count, current_timestamp\r\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\r\n\r\nspark \u003d SparkSession.builder\\\r\n    .appName(\u0027fhvhv_cleaned\u0027)\\\r\n    .master(\u0027local\u0027)\\\r\n    .getOrCreate()\r\n\r\nschema \u003d StructType([\r\n    StructField(\"hvfhs_license_num\", StringType(), True),\r\n    StructField(\"dispatching_base_num\", StringType(), True),\r\n    StructField(\"originating_base_num\", StringType(), True),\r\n    StructField(\"request_datetime\", StringType(), True),\r\n    StructField(\"on_scene_datetime\", StringType(), True),\r\n    StructField(\"pickup_datetime\", StringType(), True),\r\n    StructField(\"dropoff_datetime\", StringType(), True),\r\n    StructField(\"PULocationID\", IntegerType(), True),\r\n    StructField(\"DOLocationID\", IntegerType(), True),\r\n    StructField(\"trip_miles\", FloatType(), True),\r\n    StructField(\"trip_time\", IntegerType(), True),\r\n    StructField(\"base_passenger_fare\", FloatType(), True),\r\n    StructField(\"tolls\", FloatType(), True),\r\n    StructField(\"bcf\", FloatType(), True),\r\n    StructField(\"sales_tax\", FloatType(), True),\r\n    StructField(\"congestion_surcharge\", FloatType(), True),\r\n    StructField(\"airport_fee\", FloatType(), True),\r\n    StructField(\"tips\", FloatType(), True),\r\n    StructField(\"driver_pay\", FloatType(), True),\r\n    StructField(\"shared_request_flag\", StringType(), True),\r\n    StructField(\"shared_match_flag\", StringType(), True),\r\n    StructField(\"access_a_ride_flag\", StringType(), True),\r\n    StructField(\"wav_request_flag\", StringType(), True),\r\n    StructField(\"wav_match_flag\", StringType(), True)\r\n])\r\n\r\ndf \u003d spark.read.csv(\"hdfs://nodemastertah:9000/NYCtaxi/dataset/fhvhv/fhvhv_csv/*.csv\", header\u003dTrue, schema\u003dschema)\r\n\r\ndf \u003d  df.withColumn(\"request_datetime\", col(\"request_datetime\").cast(\"timestamp\")) \\\r\n    .withColumn(\"on_scene_datetime\", col(\"on_scene_datetime\").cast(\"timestamp\")) \\\r\n    .withColumn(\"pickup_datetime\", col(\"pickup_datetime\").cast(\"timestamp\")) \\\r\n    .withColumn(\"dropoff_datetime\", col(\"dropoff_datetime\").cast(\"timestamp\"))\\\r\n    .withColumn(\"PULocationID\", col(\"PULocationID\").cast(\"double\")) \\\r\n    .withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(\"double\")) \\\r\n    .withColumn(\"trip_miles\", col(\"trip_miles\").cast(\"double\")) \\\r\n    .withColumn(\"trip_time\", col(\"trip_time\").cast(\"double\")) \\\r\n    .withColumn(\"base_passenger_fare\", col(\"base_passenger_fare\").cast(\"double\")) \\\r\n    .withColumn(\"tolls\", col(\"tolls\").cast(\"double\")) \\\r\n    .withColumn(\"bcf\", col(\"bcf\").cast(\"double\")) \\\r\n    .withColumn(\"sales_tax\", col(\"sales_tax\").cast(\"double\")) \\\r\n    .withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(\"double\")) \\\r\n    .withColumn(\"airport_fee\", col(\"airport_fee\").cast(\"double\")) \\\r\n    .withColumn(\"tips\", col(\"tips\").cast(\"double\")) \\\r\n    .withColumn(\"driver_pay\", col(\"driver_pay\").cast(\"double\"))\r\n\r\ndf.printSchema()\r\ndf.show(5)\r\n\r\ndf_filled \u003d df.withColumn(\r\n    \"on_scene_datetime\",\r\n    when(col(\"on_scene_datetime\").isNull(), lit(None)).otherwise(col(\"on_scene_datetime\").cast(\"timestamp\"))\r\n).fillna({\r\n    \"originating_base_num\": \"N/A\",\r\n    \"airport_fee\": 0\r\n}).withColumn(\r\n    \"wav_match_flag\",\r\n    when(col(\"wav_match_flag\").isNull(), col(\"wav_request_flag\")).otherwise(col(\"wav_match_flag\"))\r\n)\r\n\r\ndf_add \u003d df_filled.withColumn(\r\n    \"Total_Amt\",\r\n    (col(\"base_passenger_fare\") +\r\n     col(\"tolls\") +\r\n     col(\"tips\") +\r\n     col(\"congestion_surcharge\") +\r\n     col(\"airport_fee\") +\r\n     col(\"driver_pay\"))\r\n)\r\n\r\n\r\ndf_cleaned_fhvhv \u003d df_add.filter(col(\"trip_miles\") \u003e 0)\r\n\r\nlegal_rows_count \u003d df_cleaned_fhvhv.count()\r\n\r\nprint(f\"clean data:\")\r\n\r\ndf_cleaned_fhvhv.show(5)\r\nprint(f\"Number of legal rows: {legal_rows_count}\")\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import count\r\n\r\nlocation_heatmap \u003d df_cleaned.groupBy(\"PULocationID\", \"DOLocationID\").agg(count(\"*\").alias(\"trip_count\"))\r\nlocation_heatmap \u003d location_heatmap.orderBy(col(\"trip_count\").desc())\r\n\r\nz.show(location_heatmap)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\ncongestion_effect \u003d df_cleaned.groupBy(\"congestion_surcharge\").agg({\"base_passenger_fare\": \"sum\"}).orderBy(\"congestion_surcharge\")\r\n\r\nz.show(congestion_effect)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import hour\r\n\r\ndf \u003d df_cleaned.withColumn(\"hour\", hour(\"pickup_datetime\"))\r\n\r\ndemand_supply \u003d df.groupBy(\"hour\", \"PULocationID\").count()\r\n\r\nz.show(demand_supply)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nlow_profit_routes \u003d df_cleaned.groupBy(\"PULocationID\", \"DOLocationID\").agg(sum(\"base_passenger_fare\").alias(\"total_revenue\"))\r\n\r\nz.show(low_profit_routes.filter(col(\"total_revenue\") \u003c 10))\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import unix_timestamp\r\n\r\ndf \u003d df_cleaned.withColumn(\"trip_duration\", \r\n    (unix_timestamp(\"dropoff_datetime\") - unix_timestamp(\"pickup_datetime\")) / 60)\r\ndf \u003d df.withColumn(\"pickup_hour\", hour(\"pickup_datetime\"))\r\n\r\nhourly_duration \u003d df.groupBy(\"pickup_hour\").agg({\"trip_duration\": \"avg\"}).orderBy(\"pickup_hour\")\r\n\r\nz.show(hourly_duration)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import dayofweek, count\r\n\r\ntrip_demand \u003d df_cleaned_fhvhv.groupBy(dayofweek(\"pickup_datetime\").alias(\"Day_of_Week\")) \\\r\n    .agg(count(\"*\").alias(\"Trip_Count\")) \\\r\n    .orderBy(\"Day_of_Week\")\r\n\r\nz.show(trip_demand)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import (col, avg)\r\n\r\ntip_percentage \u003d df_cleaned_fhvhv.withColumn(\"tip_percent\", (col(\"tips\") / col(\"base_passenger_fare\")) * 100) \\\r\n    .groupBy(\"shared_request_flag\") \\\r\n    .agg(avg(\"tip_percent\").alias(\"Avg_Tip_Percentage\")) \\\r\n    .orderBy(\"Avg_Tip_Percentage\", ascending\u003dFalse)\r\n\r\nz.show(tip_percentage)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import count\r\n\r\nairport_trips \u003d df_cleaned_fhvhv.filter(col(\"PULocationID\").isin([132, 138]) | col(\"DOLocationID\").isin([132, 138])) \\\r\n    .groupBy(\"PULocationID\", \"DOLocationID\") \\\r\n    .agg(count(\"*\").alias(\"Trip_Count\")) \\\r\n    .orderBy(\"Trip_Count\", ascending\u003dFalse)\r\n\r\nz.show(airport_trips)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import avg\r\n\r\nearnings_vs_distance \u003d df_cleaned_fhvhv.groupBy(\"trip_miles\") \\\r\n    .agg(avg(\"driver_pay\").alias(\"Avg_Driver_Pay\")) \\\r\n    .orderBy(\"trip_miles\")\r\n\r\nz.show(earnings_vs_distance)\r\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}